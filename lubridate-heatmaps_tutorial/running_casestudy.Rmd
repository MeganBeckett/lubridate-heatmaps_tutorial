---
title: "Case Study: Running activities"
author: "Megan Beckett"
date: "16 August 2018"
output:
  html_notebook:
    fig_height: 7
    fig_width: 10
    toc: yes
---
# Introduction

This follows on from investigating the lubridate package within the tidyverse and putting some of the features into practice by looking at running activity data over time.

I was interested to investigate some ways of plott my running activities over time. The data is a csv export from Garmin Connect.

# Load packages needed
```{r message=FALSE,warning=FALSE}
library(lubridate)
library(dplyr)
library(ggplot2)
library(skimr)
library(summarytools)
library(RColorBrewer)
```

# Read in data
```{r}
activities <- read.csv("data/Activities.csv", stringsAsFactors = FALSE)
```

# Initial view of data
Notes:

- I normally use a combination of str(), summary(), glimpse() to do this and recently explored skim().
- For **skim()**, I like how it splits the summary statistics across variable type and shows a basic histogram for numerical types.
- Missing values are also shown and this, along with the histograms, gives some indication of what to explore further.
- Subsequent to this, I have now used the package **summarytools** and specifically, dfSummary(). The histogram plots are even better (although render quite small) and the developers are working to improve the html output to work with Rmarkdown. 
- See this vignette: https://cran.r-project.org/web/packages/summarytools/vignettes/Recommendations-rmarkdown.html

```{r}
dim(activities)
#str(activities)
#summary(activities)
glimpse(activities)
#skim(activities)
```

# Tidy up data
## Extract variables of interest
Many of the columns are empty so let's create a smaller subset of those we are interested in
```{r}
# Create subset of variables
running <- subset(activities, select = c(Activity.Type, Date, Distance, Calories, Time, 
                                            Avg.Pace, Elev.Gain))

# View the classes of the subset of data
lapply(running, class)
```

## Transform data types
read.csv imported some of the the numbers, dates and times as characters, so let's fix this. Also, convert Activity.Type to factor to see if there is more than one level.

```{r message=FALSE,warning=FALSE}
# Numeric values
# Substitute 1000 comma separator then convert to numeric
running$Calories <- as.numeric(gsub(",", "", running$Calories))
running$Elev.Gain <- as.numeric(gsub(",", "", running$Elev.Gain))

# Date-time columns (Date, Time, Avg.Pace, Best.Pace)
running$Date = ymd_hms(activities$Date)

# TODO Figure out how to convert different time durations to actual times 
#running$Duration <- ms(running$Time)
#running$Avg.Pace <- ms(running$Avg.Pace)
#running$Best.Pace <- ms(running$Best.Pace)

# Convert activity type to factor
running$Activity.Type <- as.factor(running$Activity.Type)
levels(running$Activity.Type)
```

View data again using summarytools package
```{r}
view(dfSummary(running), method = 'render')
```

## Subset again to only look at last 3 full year's of data
```{r}
running <- subset(running, running$Date >= "2016-01-01")
```

# Create new variables
```{r}
running$year <- year(running$Date)
running$month <- month(running$Date, label=TRUE)
running$week <- week(running$Date)
running$wday <- wday(running$Date, label=TRUE, abbr=FALSE)
running$hour <- hour(running$Date)

week <- c("Sunday", "Saturday", "Friday", "Thursday", "Wednesday", "Tuesday", "Monday")
running$wday <- factor(running$wday, levels = week)
```

# Exploratory visualisation
Use dplyr to group and summarise and and create some plots.

```{r}
# Create summary
year_month <- running %>%
  group_by(year, month) %>%
  summarise(total_runs = n(), total_distance = sum(Distance))
```

```{r}
# Plot data

```

# Heatmaps
## Weekly pattern - most popular times to run during the days of the week
```{r}
# Create a complete grid to include all possible combinations of weekday and hour even if no data
hour = c(0:23)
grid = expand.grid(week, hour)

# Group by week day, then hour and summarise by counting number of activities per group
heatmap_runs <- running %>% 
  group_by(wday, hour) %>% 
  summarise(no_runs = n())

# Join grid and heatmap_runs
# If you don't do this, heatmap won't show the full week, and have blank tiles for missing values instead of rather showing 0 runs/activity
heatmap_runs_full = heatmap_runs %>%
  right_join(grid, by = c("wday"="Var1", "hour"="Var2")) 

# Replace NA with 0
heatmap_runs_full[is.na(heatmap_runs_full)] <- 0

# Plot heatmap using ggplot
ggplot(heatmap_runs_full, aes(x=hour, y=wday)) + 
  geom_tile(aes(fill=no_runs), colour="white") + 
  scale_fill_gradient(name = "No. of runs", low = "white", high =  "red") + 
  scale_x_continuous(breaks=seq(0,23,1)) + ggtitle("Heatmap showing weekly activity pattern")
```


```{r}
# Using ColorBrewer to generate pallette

display.brewer.all()

pal <- colorRampPalette(brewer.pal(9, "YlOrRd"))(100)

ggplot(heatmap_runs_full, aes(x=hour, y=wday)) + 
  geom_tile(aes(fill=no_runs), colour="white") + 
  scale_fill_gradientn(name = "No. of runs", colours=c("white", pal)) + 
  scale_x_continuous(breaks=seq(0,23,1)) + ggtitle("Heatmap showing weekly activity pattern")

```

```{r}
# Save plot
ggsave("results/heatmap_weekly_counts.png", width = 10, height = 7)
```
## Weekly pattern - average distance run at different times during the week

```{r}
# Group by week day, then hour and summarise by calculating mean distance per group
heatmap_dist <- running %>% 
  group_by(wday, hour) %>% 
  summarise(mean_dist = mean(Distance))

# Join grid and heatmap_dist
heatmap_dist_full = heatmap_dist %>%
  right_join(grid, by = c("wday"="Var1", "hour"="Var2")) 

# Replace NA with 0
heatmap_dist_full[is.na(heatmap_dist_full)] <- 0

# Plot heatmap using ggplot
pal <- colorRampPalette(brewer.pal(9, "YlGnBu"))(100)
ggplot(heatmap_dist_full, aes(x=hour, y=wday)) + 
  geom_tile(aes(fill=mean_dist), colour="white") + 
  scale_fill_gradientn(name = "Mean distance", colours=c("white", pal)) + 
  scale_x_continuous(breaks=seq(0,23,1)) + ggtitle("Heatmap showing weekly activity pattern")
```

Mmmm...that doesn't look right - what happened at 2pm on a Sunday?! Let's investigate.
```{r}
running_outliers = subset(running, Distance >=50)
running_outliers

```

Firstly, look at the average pace of entries 345 and 352. This is rather quick for a run! As this is my own data, I know what these outliers are from!  These were actually cycles where I didn't classify the activities correctly. Secondly, the 65km entry on 13 August was when I used my Garmin watch to measure how far we travelled on a boat in Brazil :) So, let's remove these three entries. 

```{r}
running <- subset(running, Distance <=60)

# And create the graphs again above. 
# Repeated here just for ease of reference.

# Group by week day, then hour and summarise by calculating mean distance per group
heatmap_dist <- running %>% 
  group_by(wday, hour) %>% 
  summarise(mean_dist = mean(Distance))

# Join grid and heatmap_dist
heatmap_dist_full = heatmap_dist %>%
  right_join(grid, by = c("wday"="Var1", "hour"="Var2")) 

# Replace NA with 0
heatmap_dist_full[is.na(heatmap_dist_full)] <- 0

# Plot heatmap using ggplot
pal <- colorRampPalette(brewer.pal(9, "YlGnBu"))(100)
ggplot(heatmap_dist_full, aes(x=hour, y=wday)) + 
  geom_tile(aes(fill=mean_dist), colour="white") + 
  scale_fill_gradientn(name = "Mean distance", colours=c("white", pal)) + 
  scale_x_continuous(breaks=seq(0,23,1)) + ggtitle("Heatmap showing weekly activity pattern")
```

```{r}
# Save plot
ggsave("results/heatmap_weekly_dist.png", width = 10, height = 7)
```

## Calendar heat map

```{r}
source ("calendarHeat.R")

calendarHeat(running$Date, running$Distance, varname = "running activities and distances", color = "y2b", ncolors=20)

```



